[2026-02-19 14:58:24] OUT_DIR=/home/rocc/first/task1-artifacts-20260219-145824
[2026-02-19 14:58:24] RUN_LOG_FILE=/home/rocc/first/task1-artifacts-20260219-145824/run.log
[2026-02-19 14:58:24] === Startup begin ===
[2026-02-19 14:58:24] Waiting for Kubernetes API
[2026-02-19 14:58:24] Waiting for nodes Ready
[2026-02-19 14:58:24] Dump cluster state
[2026-02-19 14:58:27] Restart in ns=kong
Waiting for deployment "kong-kong" rollout to finish: 1 old replicas are pending termination...
Waiting for deployment "kong-kong" rollout to finish: 1 old replicas are pending termination...
deployment "kong-kong" successfully rolled out
[2026-02-19 14:58:54] Restart in ns=monitoring
Waiting for deployment "fake-gpu-metrics" rollout to finish: 1 old replicas are pending termination...
Waiting for deployment "fake-gpu-metrics" rollout to finish: 1 old replicas are pending termination...
deployment "fake-gpu-metrics" successfully rolled out
deployment "kong-throttle-webhook" successfully rolled out
Waiting for deployment "tenant-api" rollout to finish: 1 old replicas are pending termination...
Waiting for deployment "tenant-api" rollout to finish: 1 old replicas are pending termination...
deployment "tenant-api" successfully rolled out
[2026-02-19 15:00:15] Restart in ns=tenant-a
Waiting for deployment "fake-llm" rollout to finish: 1 old replicas are pending termination...
Waiting for deployment "fake-llm" rollout to finish: 1 old replicas are pending termination...
deployment "fake-llm" successfully rolled out
deployment "litellm" successfully rolled out
[2026-02-19 15:00:22] Restart in ns=tenant-b
Waiting for deployment "litellm" rollout to finish: 1 old replicas are pending termination...
Waiting for deployment "litellm" rollout to finish: 1 old replicas are pending termination...
deployment "litellm" successfully rolled out
[2026-02-19 15:00:26] Wait pods Ready ns=monitoring selector=app=fake-gpu-metrics
[2026-02-19 15:00:26] Wait pods Ready ns=monitoring selector=app=kong-throttle-webhook
[2026-02-19 15:00:26] Wait pods Ready ns=tenant-a selector=app=fake-llm
[2026-02-19 15:00:27] Wait pods Ready ns=tenant-a selector=app=litellm
[2026-02-19 15:00:27] Wait pods Ready ns=tenant-b selector=app=litellm
[2026-02-19 15:00:29] Port-forward ns=kong svc/kong-kong-proxy 28080:80 (log=/home/rocc/first/task1-artifacts-20260219-145824/pf-kong.log)
[2026-02-19 15:00:31] Listening OK on :28080
[2026-02-19 15:00:32] Port-forward ns=monitoring svc/kong-throttle-webhook 28083:8080 (log=/home/rocc/first/task1-artifacts-20260219-145824/pf-webhook.log)
[2026-02-19 15:00:34] Listening OK on :28083
[2026-02-19 15:00:35] Port-forward ns=monitoring svc/fake-gpu-metrics 28084:8080 (log=/home/rocc/first/task1-artifacts-20260219-145824/pf-gpu.log)
[2026-02-19 15:00:37] Listening OK on :28084
[2026-02-19 15:00:37] Wait local HTTP: webhook url=http://127.0.0.1:28083/healthz
[2026-02-19 15:00:38] OK: webhook local HTTP reachable on attempt 1
[2026-02-19 15:00:38] Wait local HTTP: gpu url=http://127.0.0.1:28084/healthz
[2026-02-19 15:00:39] OK: gpu local HTTP reachable on attempt 1
[2026-02-19 15:00:40] === Verify start (task requirement proof) ===
[2026-02-19 15:00:40] Wait HTTP 200: kong-health-tenant-a (tries=60, sleep=2s)
[2026-02-19 15:01:22] OK: kong-health-tenant-a became HTTP 200 on attempt 21
[2026-02-19 15:01:22] Wait HTTP 200: kong-health-tenant-b (tries=60, sleep=2s)
[2026-02-19 15:01:23] OK: kong-health-tenant-b became HTTP 200 on attempt 1
[2026-02-19 15:01:23] Wait HTTP 200: kong-models-tenant-a (tries=60, sleep=2s)
[2026-02-19 15:01:23] OK: kong-models-tenant-a became HTTP 200 on attempt 1
[2026-02-19 15:01:23] [A] Health checks
HTTP/1.1 200 OK
Content-Type: application/json
Content-Length: 113
Connection: keep-alive
RateLimit-Remaining: 3
X-RateLimit-Remaining-Second: 3
X-RateLimit-Limit-Second: 5
RateLimit-Reset: 1
RateLimit-Limit: 5
date: Thu, 19 Feb 2026 07:01:22 GMT
server: uvicorn
X-Kong-Upstream-Latency: 240
X-Kong-Proxy-Latency: 1
Via: 1.1 kong/3.9.1
X-Kong-Request-Id: 99d3fd048f12ec5f4366f51b0b71af16

{"healthy_endpoints":[{"model":"openai/fake-llm","api_base":"http://fake-llm:8080/v1"}],"unhealthy_endpoints":[]}HTTP/1.1 200 OK
Content-Type: application/json
Content-Length: 145
Connection: keep-alive
date: Thu, 19 Feb 2026 07:01:23 GMT
server: uvicorn
X-Kong-Upstream-Latency: 181
X-Kong-Proxy-Latency: 1
Via: 1.1 kong/3.9.1
X-Kong-Request-Id: 8ff3be3ef64b2d6246041b4bbe67771b

{"healthy_endpoints":[{"model":"openai/gpt-3.5-turbo","api_base":"http://fake-llm.tenant-a.svc.cluster.local:8080/v1"}],"unhealthy_endpoints":[]}10
[2026-02-19 15:01:24] [B] LOW util -> expect rl disabled=true -> no 429
ok util=0
0
HTTP/1.0 200 OK
Server: BaseHTTP/0.6 Python/3.11.14
Date: Thu, 19 Feb 2026 07:01:26 GMT
Content-Type: text/plain; charset=utf-8

ok util=0 threshold=5 disabled=true patch_status=200
rl_disabled=true
200
200
200
200
200
200
200
200
200
200
[2026-02-19 15:01:28] [C] HIGH util -> expect rl disabled=false -> see 429
ok util=10
10
HTTP/1.0 200 OK
Server: BaseHTTP/0.6 Python/3.11.14
Date: Thu, 19 Feb 2026 07:01:30 GMT
Content-Type: text/plain; charset=utf-8

ok util=10 threshold=5 disabled=false patch_status=200
rl_disabled=false
200
200
200
200
200
200
200
200
200
200
200
200
200
200
200
200
200
200
200
200
[2026-02-19 15:01:32] === Verify end ===
OUT_DIR=/home/rocc/first/task1-artifacts-20260219-145824
Kong:    http://127.0.0.1:28080
Webhook: http://127.0.0.1:28083
GPU:     http://127.0.0.1:28084
[2026-02-19 15:01:32] === Startup end ===
[2026-02-19 15:01:32] Artifacts saved: /home/rocc/first/task1-artifacts-20260219-145824
