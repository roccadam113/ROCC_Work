[2026-02-19 15:13:00] OUT_DIR=/home/rocc/first/task1-artifacts-20260219-151300
[2026-02-19 15:13:00] RUN_LOG_FILE=/home/rocc/first/task1-artifacts-20260219-151300/run.log
[2026-02-19 15:13:00] === Startup begin ===
[2026-02-19 15:13:00] Waiting for Kubernetes API
[2026-02-19 15:13:00] Waiting for nodes Ready
[2026-02-19 15:13:00] Dump cluster state
[2026-02-19 15:13:03] Restart in ns=kong
Waiting for deployment "kong-kong" rollout to finish: 1 old replicas are pending termination...
Waiting for deployment "kong-kong" rollout to finish: 1 old replicas are pending termination...
deployment "kong-kong" successfully rolled out
[2026-02-19 15:13:30] Restart in ns=monitoring
Waiting for deployment "fake-gpu-metrics" rollout to finish: 1 old replicas are pending termination...
Waiting for deployment "fake-gpu-metrics" rollout to finish: 1 old replicas are pending termination...
deployment "fake-gpu-metrics" successfully rolled out
deployment "kong-throttle-webhook" successfully rolled out
Waiting for deployment "tenant-api" rollout to finish: 1 old replicas are pending termination...
Waiting for deployment "tenant-api" rollout to finish: 1 old replicas are pending termination...
deployment "tenant-api" successfully rolled out
[2026-02-19 15:16:51] Restart in ns=tenant-a
Waiting for deployment "fake-llm" rollout to finish: 1 old replicas are pending termination...
Waiting for deployment "fake-llm" rollout to finish: 1 old replicas are pending termination...
deployment "fake-llm" successfully rolled out
deployment "litellm" successfully rolled out
[2026-02-19 15:16:56] Restart in ns=tenant-b
Waiting for deployment "litellm" rollout to finish: 1 old replicas are pending termination...
Waiting for deployment "litellm" rollout to finish: 1 old replicas are pending termination...
deployment "litellm" successfully rolled out
[2026-02-19 15:16:59] Wait pods Ready ns=monitoring selector=app=fake-gpu-metrics
[2026-02-19 15:16:59] Wait pods Ready ns=monitoring selector=app=kong-throttle-webhook
[2026-02-19 15:16:59] Wait pods Ready ns=tenant-a selector=app=fake-llm
[2026-02-19 15:16:59] Wait pods Ready ns=tenant-a selector=app=litellm
[2026-02-19 15:17:00] Wait pods Ready ns=tenant-b selector=app=litellm
[2026-02-19 15:17:02] Port-forward ns=kong pod/kong-kong-6c56fd68bc-nm6qt 28080:8000 (log=/home/rocc/first/task1-artifacts-20260219-151300/pf-kong.log)
[2026-02-19 15:17:04] Listening OK on :28080
[2026-02-19 15:17:05] Port-forward ns=monitoring svc/kong-throttle-webhook 28083:8080 (log=/home/rocc/first/task1-artifacts-20260219-151300/pf-webhook.log)
[2026-02-19 15:17:07] Listening OK on :28083
[2026-02-19 15:17:08] Port-forward ns=monitoring svc/fake-gpu-metrics 28084:8080 (log=/home/rocc/first/task1-artifacts-20260219-151300/pf-gpu.log)
[2026-02-19 15:17:10] Listening OK on :28084
[2026-02-19 15:17:10] Wait local HTTP: webhook url=http://127.0.0.1:28083/healthz
[2026-02-19 15:17:11] OK: webhook local HTTP reachable on attempt 1
[2026-02-19 15:17:11] Wait local HTTP: gpu url=http://127.0.0.1:28084/healthz
[2026-02-19 15:17:12] OK: gpu local HTTP reachable on attempt 1
[2026-02-19 15:17:12] === Verify start (task requirement proof) ===
[2026-02-19 15:17:12] Wait HTTP 200: kong-health-tenant-a (tries=60, sleep=2s)
[2026-02-19 15:17:40] OK: kong-health-tenant-a became HTTP 200 on attempt 14
[2026-02-19 15:17:40] Wait HTTP 200: kong-health-tenant-b (tries=60, sleep=2s)
[2026-02-19 15:17:41] OK: kong-health-tenant-b became HTTP 200 on attempt 1
[2026-02-19 15:17:41] Wait HTTP 200: kong-models-tenant-a (tries=60, sleep=2s)
[2026-02-19 15:17:41] OK: kong-models-tenant-a became HTTP 200 on attempt 1
[2026-02-19 15:17:41] [A] Health checks
HTTP/1.1 200 OK
Content-Type: application/json
Content-Length: 113
Connection: keep-alive
X-RateLimit-Limit-Second: 5
RateLimit-Limit: 5
RateLimit-Remaining: 3
RateLimit-Reset: 1
X-RateLimit-Remaining-Second: 3
date: Thu, 19 Feb 2026 07:17:40 GMT
server: uvicorn
X-Kong-Upstream-Latency: 385
X-Kong-Proxy-Latency: 1
Via: 1.1 kong/3.9.1
X-Kong-Request-Id: 667f362ef053cb2bfed6674b6a6f9d41

{"healthy_endpoints":[{"model":"openai/fake-llm","api_base":"http://fake-llm:8080/v1"}],"unhealthy_endpoints":[]}HTTP/1.1 200 OK
Content-Type: application/json
Content-Length: 145
Connection: keep-alive
date: Thu, 19 Feb 2026 07:17:40 GMT
server: uvicorn
X-Kong-Upstream-Latency: 229
X-Kong-Proxy-Latency: 0
Via: 1.1 kong/3.9.1
X-Kong-Request-Id: fe17036027cbdf6c7d77c7272829d963

{"healthy_endpoints":[{"model":"openai/gpt-3.5-turbo","api_base":"http://fake-llm.tenant-a.svc.cluster.local:8080/v1"}],"unhealthy_endpoints":[]}10
[2026-02-19 15:17:42] [B] LOW util -> expect rl disabled=true -> no 429
ok util=0
0
HTTP/1.0 200 OK
Server: BaseHTTP/0.6 Python/3.11.14
Date: Thu, 19 Feb 2026 07:17:45 GMT
Content-Type: text/plain; charset=utf-8

ok util=0 threshold=5 disabled=true patch_status=200
rl_disabled=true
200
200
200
200
200
200
200
200
200
200
[2026-02-19 15:17:46] [C] HIGH util -> expect rl disabled=false -> see 429
ok util=10
10
HTTP/1.0 200 OK
Server: BaseHTTP/0.6 Python/3.11.14
Date: Thu, 19 Feb 2026 07:17:48 GMT
Content-Type: text/plain; charset=utf-8

ok util=10 threshold=5 disabled=false patch_status=200
rl_disabled=false
200
200
200
200
200
200
200
200
200
200
200
200
200
200
200
200
200
200
200
200
200
200
200
200
429
200
200
200
200
200
200
200
200
200
200
200
200
200
200
200
200
200
200
200
200
200
200
200
200
200
[2026-02-19 15:17:52] === Verify end ===
OUT_DIR=/home/rocc/first/task1-artifacts-20260219-151300
Kong:    http://127.0.0.1:28080
Webhook: http://127.0.0.1:28083
GPU:     http://127.0.0.1:28084
[2026-02-19 15:17:52] === Startup end ===
[2026-02-19 15:17:52] Artifacts saved: /home/rocc/first/task1-artifacts-20260219-151300
