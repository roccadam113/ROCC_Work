[2026-02-19 15:06:21] OUT_DIR=/home/rocc/first/task1-artifacts-20260219-150621
[2026-02-19 15:06:21] RUN_LOG_FILE=/home/rocc/first/task1-artifacts-20260219-150621/run.log
[2026-02-19 15:06:21] === Startup begin ===
[2026-02-19 15:06:21] Waiting for Kubernetes API
[2026-02-19 15:06:21] Waiting for nodes Ready
[2026-02-19 15:06:21] Dump cluster state
[2026-02-19 15:06:24] Restart in ns=kong
Waiting for deployment "kong-kong" rollout to finish: 1 old replicas are pending termination...
Waiting for deployment "kong-kong" rollout to finish: 1 old replicas are pending termination...
deployment "kong-kong" successfully rolled out
[2026-02-19 15:06:50] Restart in ns=monitoring
Waiting for deployment "fake-gpu-metrics" rollout to finish: 1 old replicas are pending termination...
Waiting for deployment "fake-gpu-metrics" rollout to finish: 1 old replicas are pending termination...
deployment "fake-gpu-metrics" successfully rolled out
deployment "kong-throttle-webhook" successfully rolled out
Waiting for deployment "tenant-api" rollout to finish: 1 old replicas are pending termination...
Waiting for deployment "tenant-api" rollout to finish: 1 old replicas are pending termination...
deployment "tenant-api" successfully rolled out
[2026-02-19 15:07:38] Restart in ns=tenant-a
Waiting for deployment "fake-llm" rollout to finish: 1 old replicas are pending termination...
Waiting for deployment "fake-llm" rollout to finish: 1 old replicas are pending termination...
deployment "fake-llm" successfully rolled out
deployment "litellm" successfully rolled out
[2026-02-19 15:07:42] Restart in ns=tenant-b
Waiting for deployment "litellm" rollout to finish: 1 old replicas are pending termination...
Waiting for deployment "litellm" rollout to finish: 1 old replicas are pending termination...
deployment "litellm" successfully rolled out
[2026-02-19 15:07:46] Wait pods Ready ns=monitoring selector=app=fake-gpu-metrics
[2026-02-19 15:07:46] Wait pods Ready ns=monitoring selector=app=kong-throttle-webhook
[2026-02-19 15:07:46] Wait pods Ready ns=tenant-a selector=app=fake-llm
[2026-02-19 15:07:47] Wait pods Ready ns=tenant-a selector=app=litellm
[2026-02-19 15:07:47] Wait pods Ready ns=tenant-b selector=app=litellm
[2026-02-19 15:07:49] Port-forward ns=kong pod/kong-kong-859c59b77c-fz9jg 28080:8000 (log=/home/rocc/first/task1-artifacts-20260219-150621/pf-kong.log)
[2026-02-19 15:07:51] Listening OK on :28080
[2026-02-19 15:07:52] Port-forward ns=monitoring svc/kong-throttle-webhook 28083:8080 (log=/home/rocc/first/task1-artifacts-20260219-150621/pf-webhook.log)
[2026-02-19 15:07:54] Listening OK on :28083
[2026-02-19 15:07:55] Port-forward ns=monitoring svc/fake-gpu-metrics 28084:8080 (log=/home/rocc/first/task1-artifacts-20260219-150621/pf-gpu.log)
[2026-02-19 15:07:57] Listening OK on :28084
[2026-02-19 15:07:57] Wait local HTTP: webhook url=http://127.0.0.1:28083/healthz
[2026-02-19 15:07:59] OK: webhook local HTTP reachable on attempt 1
[2026-02-19 15:07:59] Wait local HTTP: gpu url=http://127.0.0.1:28084/healthz
[2026-02-19 15:08:00] OK: gpu local HTTP reachable on attempt 1
[2026-02-19 15:08:00] === Verify start (task requirement proof) ===
[2026-02-19 15:08:00] Wait HTTP 200: kong-health-tenant-a (tries=60, sleep=2s)
[2026-02-19 15:08:32] OK: kong-health-tenant-a became HTTP 200 on attempt 16
[2026-02-19 15:08:32] Wait HTTP 200: kong-health-tenant-b (tries=60, sleep=2s)
[2026-02-19 15:08:34] OK: kong-health-tenant-b became HTTP 200 on attempt 2
[2026-02-19 15:08:35] Wait HTTP 200: kong-models-tenant-a (tries=60, sleep=2s)
[2026-02-19 15:08:35] OK: kong-models-tenant-a became HTTP 200 on attempt 1
[2026-02-19 15:08:35] [A] Health checks
HTTP/1.1 200 OK
Content-Type: application/json
Content-Length: 113
Connection: keep-alive
X-RateLimit-Remaining-Second: 3
X-RateLimit-Limit-Second: 5
RateLimit-Limit: 5
RateLimit-Remaining: 3
RateLimit-Reset: 1
date: Thu, 19 Feb 2026 07:08:34 GMT
server: uvicorn
X-Kong-Upstream-Latency: 303
X-Kong-Proxy-Latency: 1
Via: 1.1 kong/3.9.1
X-Kong-Request-Id: 524d5c7bcce47a5fdd2d4117506a7335

{"healthy_endpoints":[{"model":"openai/fake-llm","api_base":"http://fake-llm:8080/v1"}],"unhealthy_endpoints":[]}HTTP/1.1 200 OK
Content-Type: application/json
Content-Length: 145
Connection: keep-alive
date: Thu, 19 Feb 2026 07:08:35 GMT
server: uvicorn
X-Kong-Upstream-Latency: 392
X-Kong-Proxy-Latency: 3
Via: 1.1 kong/3.9.1
X-Kong-Request-Id: 48076310aae60c0c8dea703f49afa312

{"healthy_endpoints":[{"model":"openai/gpt-3.5-turbo","api_base":"http://fake-llm.tenant-a.svc.cluster.local:8080/v1"}],"unhealthy_endpoints":[]}10
[2026-02-19 15:08:37] [B] LOW util -> expect rl disabled=true -> no 429
ok util=0
0
HTTP/1.0 200 OK
Server: BaseHTTP/0.6 Python/3.11.14
Date: Thu, 19 Feb 2026 07:08:39 GMT
Content-Type: text/plain; charset=utf-8

ok util=0 threshold=5 disabled=true patch_status=200
rl_disabled=true
200
200
200
200
200
200
200
200
200
200
[2026-02-19 15:08:41] [C] HIGH util -> expect rl disabled=false -> see 429
ok util=10
10
HTTP/1.0 200 OK
Server: BaseHTTP/0.6 Python/3.11.14
Date: Thu, 19 Feb 2026 07:08:43 GMT
Content-Type: text/plain; charset=utf-8

ok util=10 threshold=5 disabled=false patch_status=200
rl_disabled=false
200
200
200
200
200
200
200
200
200
200
200
200
200
200
200
200
200
200
200
200
[2026-02-19 15:08:45] === Verify end ===
OUT_DIR=/home/rocc/first/task1-artifacts-20260219-150621
Kong:    http://127.0.0.1:28080
Webhook: http://127.0.0.1:28083
GPU:     http://127.0.0.1:28084
[2026-02-19 15:08:45] === Startup end ===
[2026-02-19 15:08:45] Artifacts saved: /home/rocc/first/task1-artifacts-20260219-150621
